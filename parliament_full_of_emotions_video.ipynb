{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLMfQL_AOcAT"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless deepface moviepy\n",
        "\n",
        "import cv2\n",
        "from deepface import DeepFace\n",
        "import moviepy.editor as mp\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "video_path = \"/content/drive/My Drive/face_videos/PSV.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d9BPuPUOlXm"
      },
      "outputs": [],
      "source": [
        "# Open the video file using OpenCV\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video file.\")\n",
        "    exit()\n",
        "\n",
        "# Get video details\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "# Define the output video path on Google Drive\n",
        "output_video_path = \"/content/drive/My Drive/face_videos/PSV_output_video.mp4\"\n",
        "\n",
        "# Create a VideoWriter object to save the output video\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# Define the text color (Lila color in BGR)\n",
        "text_color = (255, 0, 255)  # Lilac\n",
        "\n",
        "# Define the rectangle color (Green in BGR)\n",
        "rectangle_color = (0, 255, 0)  # Green\n",
        "\n",
        "# Process the video frame by frame\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Detect faces and analyze each face in the frame using DeepFace\n",
        "    try:\n",
        "        # Analyze the frame for face detection, emotion, and gender\n",
        "        results = DeepFace.analyze(frame, actions=['emotion', 'gender'], enforce_detection=False)\n",
        "\n",
        "        # Process each detected face in the frame\n",
        "        for result in results:\n",
        "            # Get face bounding box coordinates\n",
        "            x, y, w, h = result['region']['x'], result['region']['y'], result['region']['w'], result['region']['h']\n",
        "\n",
        "            # Draw a rectangle around the face (Green color)\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), rectangle_color, 2)\n",
        "\n",
        "            # Get the dominant emotion and gender probabilities\n",
        "            dominant_emotion = result['dominant_emotion']\n",
        "            gender_probabilities = result['gender']\n",
        "\n",
        "            # Determine the gender with the highest probability\n",
        "            predicted_gender = max(gender_probabilities, key=gender_probabilities.get)\n",
        "            predicted_gender_prob = gender_probabilities[predicted_gender]\n",
        "\n",
        "            # Annotate the frame with the detected emotion and the dominant gender with its probability\n",
        "            text = f\"{dominant_emotion}, {predicted_gender} ({predicted_gender_prob*100:.2f}%)\"\n",
        "            cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, text_color, 2, cv2.LINE_AA)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing frame: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Write the annotated frame to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "# Release the video capture and writer objects\n",
        "cap.release()\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EVpWPR7SXgL"
      },
      "outputs": [],
      "source": [
        "# Convert the output to a format that can be viewed in Colab // does work for some videos but not all :(\n",
        "clip = mp.VideoFileClip(output_video_path)\n",
        "clip.ipython_display(width=640)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
